{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuFPMiner_bit import cuFPMiner_bit\n",
    "from cuFPMiner_hash import cuFPMiner_hash\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output(output):\n",
    "    metrics = {}\n",
    "    \n",
    "    # Use regular expressions to find the relevant metrics\n",
    "    time_to_read_match = re.search(r\"Time to read:\\s*([\\d.]+)\\s*seconds\", output)\n",
    "    runtime_match = re.search(r\"Runtime:\\s*([\\d.]+)\\s*seconds\", output)\n",
    "    num_patterns_match = re.search(r\"Number of patterns:\\s*(\\d+)\", output)\n",
    "    memory_usage_match = re.search(r\"Memory usage:\\s*(\\d+)\\s*MB\", output)\n",
    "    peak_memory_usage_match = re.search(r\"Peak memory usage:\\s*(\\d+)\\s*MB\", output)\n",
    "    \n",
    "    if time_to_read_match:\n",
    "        metrics['time_to_read'] = float(time_to_read_match.group(1))\n",
    "    if runtime_match:\n",
    "        metrics['runtime'] = float(runtime_match.group(1))\n",
    "    if num_patterns_match:\n",
    "        metrics['number_of_patterns'] = int(num_patterns_match.group(1))\n",
    "    if memory_usage_match:\n",
    "        metrics['memory_usage_mb'] = int(memory_usage_match.group(1))\n",
    "    if peak_memory_usage_match:\n",
    "        metrics['peak_memory_usage_mb'] = int(peak_memory_usage_match.group(1))\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def run_alg(alg_path, file_path, minsup, separator, num_cores):\n",
    "\n",
    "    # Construct the command\n",
    "    command = [\n",
    "        alg_path, \n",
    "        file_path, \n",
    "        str(minsup), \n",
    "        separator, \n",
    "        str(num_cores), \n",
    "        \"/dev/null\"  # Discard output to /dev/null\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Run the command and capture the output\n",
    "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "        output = result.stdout\n",
    "\n",
    "        # Parse the output\n",
    "        metrics = parse_output(output)\n",
    "        return metrics\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error: Command failed with return code {e.returncode}\")\n",
    "        print(f\"Stderr: {e.stderr}\")\n",
    "        return None\n",
    "    except Exception as ex:\n",
    "        print(f\"Error: {ex}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "work = [\n",
    "        # [\"../../datasets/transactional/Transactional_retail.csv\", [100,90,80,70]],\n",
    "        # [\"../../datasets/transactional/Transactional_T10I4D100K.csv\", [50, 25, 10, 5]],\n",
    "        [\"../../datasets/transactional/Transactional_pumsb.csv\", [39000, 38000, 37000, 36000, 35000]],\n",
    "        # [\"../../datasets/transactional/Transactional_chess1.csv\", [2000, 1900,1800,1700,1600]],\n",
    "        # [\"../../datasets/transactional/Transactional_kosarak.csv\", [2000,3000,4000,5000,6000]],\n",
    "        ]\n",
    "sep = \"\\t\"\n",
    "\n",
    "output_dir = \"../../results/frequent_patterns/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_filename(file_path):\n",
    "    \"\"\"Clean the filename by removing everything before the last '/' and removing 'transactional' and the extension.\"\"\"\n",
    "    base_name = os.path.basename(file_path)\n",
    "    cleaned_name = base_name.replace(\"Transactional_\", \"\").split(\".\")[0]\n",
    "    return cleaned_name\n",
    "\n",
    "def run_workload(work, sep, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for file_path, min_sups in work:\n",
    "        cleaned_name = clean_filename(file_path)\n",
    "        file_output_csv = os.path.join(output_dir, f\"{cleaned_name}.csv\")\n",
    "\n",
    "        # Load existing results if the file already exists\n",
    "        if os.path.exists(file_output_csv):\n",
    "            df_existing = pd.read_csv(file_output_csv)\n",
    "            processed_combinations = set(\n",
    "                zip(df_existing[\"file\"], df_existing[\"min_sup\"], df_existing[\"algorithm\"])\n",
    "            )\n",
    "        else:\n",
    "            processed_combinations = set()\n",
    "\n",
    "        results = []\n",
    "        \n",
    "        for min_sup in min_sups:\n",
    "            # Define algorithms and configurations\n",
    "            algorithms = [\n",
    "                (\"cuFPMiner_bit_csv\", lambda: cuFPMiner_bit(file_path, min_sup, sep, 'csv', \"managed\")),\n",
    "                # (\"cuFPMiner_hash_csv\", lambda: cuFPMiner_hash(file_path, min_sup, sep, 'csv', \"managed\")),\n",
    "                (\"cuFPMiner_hash_shared_csv\", lambda: cuFPMiner_hash(file_path, min_sup, sep, 'csv', \"managed\", True))\n",
    "            ]\n",
    "\n",
    "            # Run Python-based algorithms\n",
    "            for alg_name, alg_func in algorithms:\n",
    "                if (file_path, min_sup, alg_name) in processed_combinations:\n",
    "                    continue\n",
    "\n",
    "                alg = alg_func()\n",
    "                alg.mine()\n",
    "                result = {\n",
    "                    \"algorithm\": alg_name,\n",
    "                    \"file\": file_path,\n",
    "                    \"min_sup\": min_sup,\n",
    "                    \"runtime\": alg.getRuntime(),\n",
    "                    \"patterns\": len(alg.getPatterns()),\n",
    "                    \"memory\": alg.getMemoryRSS(),\n",
    "                    \"time_to_read\": alg.getTimeToRead(),\n",
    "                }\n",
    "                results.append(result)\n",
    "                pd.DataFrame([result]).to_csv(file_output_csv, mode='a', header=not os.path.exists(file_output_csv), index=False)\n",
    "                processed_combinations.add((file_path, min_sup, alg_name))\n",
    "\n",
    "            # Run command-based algorithms\n",
    "            for alg_name, command_template in [\n",
    "                # (\"apriori\", \"./apriori\"),\n",
    "                (\"fpgrowth\", \"./fpgrowth\"),\n",
    "            ]:\n",
    "                if (file_path, min_sup, alg_name + \" 16 threads\") in processed_combinations:\n",
    "                    continue\n",
    "\n",
    "                metrics = run_alg(command_template, file_path, min_sup, sep, 16)\n",
    "                if metrics:\n",
    "                    result = {\n",
    "                        \"algorithm\": alg_name + \" 16 threads\",\n",
    "                        \"file\": file_path,\n",
    "                        \"min_sup\": min_sup,\n",
    "                        \"runtime\": metrics.get(\"runtime\", 0),\n",
    "                        \"patterns\": metrics.get(\"number_of_patterns\", 0),\n",
    "                        \"memory\": metrics.get(\"peak_memory_usage_mb\", 0),\n",
    "                        \"time_to_read\": metrics.get(\"time_to_read\", 0),\n",
    "                    }\n",
    "                    results.append(result)\n",
    "                    pd.DataFrame([result]).to_csv(file_output_csv, mode='a', header=not os.path.exists(file_output_csv), index=False)\n",
    "                    processed_combinations.add((file_path, min_sup, alg_name))\n",
    "\n",
    "        print(f\"Finished processing {file_path}\")\n",
    "\n",
    "# Main workflow\n",
    "# run_workload(work, sep, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot ../../results/frequent_patterns/pumsb_runtime_vs_min_sup.svg\n",
      "Saved plot ../../results/frequent_patterns/pumsb_patterns_vs_min_sup.svg\n",
      "Saved plot ../../results/frequent_patterns/pumsb_memory_vs_min_sup.svg\n",
      "Saved plot ../../results/frequent_patterns/kosarak_runtime_vs_min_sup.svg\n",
      "Saved plot ../../results/frequent_patterns/kosarak_patterns_vs_min_sup.svg\n",
      "Saved plot ../../results/frequent_patterns/kosarak_memory_vs_min_sup.svg\n",
      "Saved plot ../../results/frequent_patterns/chess_runtime_vs_min_sup.svg\n",
      "Saved plot ../../results/frequent_patterns/chess_patterns_vs_min_sup.svg\n",
      "Saved plot ../../results/frequent_patterns/chess_memory_vs_min_sup.svg\n",
      "Saved plot ../../results/frequent_patterns/retail_runtime_vs_min_sup.svg\n",
      "Saved plot ../../results/frequent_patterns/retail_patterns_vs_min_sup.svg\n",
      "Saved plot ../../results/frequent_patterns/retail_memory_vs_min_sup.svg\n",
      "Saved plot ../../results/frequent_patterns/T10I4D100K_runtime_vs_min_sup.svg\n",
      "Saved plot ../../results/frequent_patterns/T10I4D100K_patterns_vs_min_sup.svg\n",
      "Saved plot ../../results/frequent_patterns/T10I4D100K_memory_vs_min_sup.svg\n"
     ]
    }
   ],
   "source": [
    "fig_size = (5,5)\n",
    "\n",
    "linestyle_tuple = [\n",
    "     ('loosely dotted',        (0, (1, 10))),\n",
    "     ('dotted',                (0, (1, 1))),\n",
    "     ('densely dotted',        (0, (1, 1))),\n",
    "     ('long dash with offset', (5, (10, 3))),\n",
    "     ('loosely dashed',        (0, (5, 10))),\n",
    "     ('dashed',                (0, (5, 5))),\n",
    "     ('densely dashed',        (0, (5, 1))),\n",
    "\n",
    "     ('loosely dashdotted',    (0, (3, 10, 1, 10))),\n",
    "     ('dashdotted',            (0, (3, 5, 1, 5))),\n",
    "     ('densely dashdotted',    (0, (3, 1, 1, 1))),\n",
    "\n",
    "     ('dashdotdotted',         (0, (3, 5, 1, 5, 1, 5))),\n",
    "     ('loosely dashdotdotted', (0, (3, 10, 1, 10, 1, 10))),\n",
    "     ('densely dashdotdotted', (0, (3, 1, 1, 1, 1, 1)))]\n",
    "\n",
    "marker_shapes = ['o', 's', '^', 'D', 'v', 'p', '*', 'h', 'H', '+', 'x', 'X']\n",
    "\n",
    "# if name algorithm name contains .csv remove that part\n",
    "# if name algorithm name contains _ remove that part\n",
    "\n",
    "\n",
    "\n",
    "def plot_results(output_dir):\n",
    "    for csv_file in os.listdir(output_dir):\n",
    "        if not csv_file.endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(output_dir, csv_file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        cleaned_name = os.path.splitext(csv_file)[0]\n",
    "        \n",
    "        df[\"algorithm\"] = df[\"algorithm\"].apply(lambda x: x.replace(\"_csv\", \"\").replace(\"_\", \" \"))\n",
    "        \n",
    "        # convert memory to MB\n",
    "        df[\"memory\"] = df[\"memory\"]\n",
    "\n",
    "        metrics = [\"runtime\", \"patterns\", \"memory\"]\n",
    "        for metric in metrics:\n",
    "            plt.figure(figsize=fig_size)\n",
    "            algs = df[\"algorithm\"].unique()\n",
    "            line_color_marker = [[linestyle_tuple[i][1], f\"C{i}\", f\"{marker_shapes[i]}\"] for i in range(len(algs))]\n",
    "            sorted_methods = sorted(algs)\n",
    "            \n",
    "            \n",
    "            # for alg in df[\"algorithm\"].unique():\n",
    "            for i, alg in enumerate(sorted_methods):\n",
    "                alg_df = df[df[\"algorithm\"] == alg]\n",
    "                plt.plot(alg_df[\"min_sup\"], alg_df[metric], label=alg, marker=line_color_marker[i][2], linestyle=line_color_marker[i][0], color=line_color_marker[i][1])\n",
    "\n",
    "            plt.title(f\"{metric.capitalize()} vs Minimum Support ({cleaned_name})\")\n",
    "            plt.xlabel(\"Minimum Support\")\n",
    "            # plt.ylabel(metric.capitalize())\n",
    "            if metric == \"memory\":\n",
    "                plt.ylabel(f\"Peak Memory Usage(MB)\")\n",
    "            elif metric == \"runtime\":\n",
    "                plt.ylabel(f\"{metric.capitalize()} (s)\")\n",
    "            else:\n",
    "                plt.ylabel(f\"{metric.capitalize()}\")\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            \n",
    "            # tilt x-axis labels\n",
    "            plt.xticks(rotation=45)\n",
    "\n",
    "            plot_path = os.path.join(output_dir, f\"{cleaned_name}_{metric}_vs_min_sup.svg\")\n",
    "            plt.savefig(plot_path, format=\"svg\", transparent=True)\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"Saved plot {plot_path}\")\n",
    "\n",
    "plot_results(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
